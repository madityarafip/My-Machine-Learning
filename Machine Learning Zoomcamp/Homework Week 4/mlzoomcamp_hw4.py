# -*- coding: utf-8 -*-
"""MLZoomcamp_HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dwkpSb8U4Z2GbUSGM_8YKIEOor7_tN9f

**LIBRARY**

----
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

from sklearn.model_selection import train_test_split, KFold

from sklearn.feature_extraction import DictVectorizer

from sklearn.linear_model import LogisticRegression, Ridge

from sklearn.metrics import roc_curve, auc, roc_auc_score

from tqdm.auto import tqdm

"""**DATA PREPARATION**

------------------------------------------------------------------------------
"""

!wget --no-check-certificate https://raw.githubusercontent.com/madityarafip/My-Machine-Learning/main/Dataset/CreditScoring.csv

df = pd.read_csv('CreditScoring.csv')
df.columns = df.columns.str.lower()
df.head(3)

"""Change Feature from Numbers to Categorical"""

status_values = {
    1: 'ok',
    2: 'default',
    0: 'unk'
}

df.status = df.status.map(status_values)


home_values = {
    1: 'rent',
    2: 'owner',
    3: 'private',
    4: 'ignore',
    5: 'parents',
    6: 'other',
    0: 'unk'
}

df.home = df.home.map(home_values)

marital_values = {
    1: 'single',
    2: 'married',
    3: 'widow',
    4: 'separated',
    5: 'divorced',
    0: 'unk'
}

df.marital = df.marital.map(marital_values)

records_values = {
    1: 'no',
    2: 'yes',
    0: 'unk'
}

df.records = df.records.map(records_values)

job_values = {
    1: 'fixed',
    2: 'partime',
    3: 'freelance',
    4: 'others',
    0: 'unk'
}

df.job = df.job.map(job_values)

"""Prepare the numerical variables"""

for c in ['income', 'assets', 'debt']:
    df[c] = df[c].replace(to_replace=99999999, value=0)

"""Remove clients with unknown default status"""

df = df[df.status != 'unk'].reset_index(drop=True)

"""Create the target variable"""

df['default'] = (df.status == 'default').astype(int)
del df['status']

df.head(3)

"""**CATEGORICAL AND NUMERICAL FEATURES**

--------------------------------------------------------------------------
"""

categorical = [
               'home',
               'marital',
               'records',
               'job'  
]
numerical = [
             'seniority',
             'time',
             'age',
             'expenses',
             'income',
             'assets',
             'debt',
             'amount',
             'price'
]

"""**SPLIT DATASET**

-----------------------------------------------------
"""

HW_df = df.copy()
HW_df.isna().sum()

#80% Full Train, 20% Test
df_full_train, df_test = train_test_split(HW_df, test_size=0.2, random_state=1)

#60% Train, 20% Val (25% from Full Train -> 20%/80%)
df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)

y_train = df_train.default.values
y_val = df_val.default.values
y_test = df_test.default.values

del df_train['default']
del df_val['default']
del df_test['default']

print('Train Full:', len(df_full_train), 
      '(', round((len(df_full_train)/len(HW_df))*100, 3), '%)') 
print('Train:', len(df_train), 
      '(', round((len(df_train)/len(HW_df))*100, 3), '%)') 
print('Validation:', len(df_val), 
      '(', round((len(df_val)/len(HW_df))*100, 3), '%)') 
print('Test:', len(df_test), 
      '(', round((len(df_test)/len(HW_df))*100, 3), '%)')

"""ANS Q1:

------------------------------------------------------------------------

"""

auc_q1_values = []
for q_1 in numerical:
  auc_q1 = roc_auc_score(y_train, df_train[q_1].values).round(3)
  if auc_q1 < 0.5:
        auc_q1 = roc_auc_score(y_train, -df_train[q_1].values).round(3)
    
  auc_q1_values.append(auc_q1)
  print('Features = %10s' %q_1, '-> AUC = ', auc_q1)

"""**TRAINING THE MODEL**

--------------------------------------------------------------------------
"""

dv = DictVectorizer(sparse=False)

def OHE_DV(df, col):
  dicts = df[col].to_dict(orient='records')
  X_data = dv.fit_transform(dicts)

  return X_data

def OHE_DV_wo_fit(df, col):
  dicts = df[col].to_dict(orient='records')
  X_data = dv.transform(dicts)

  return X_data

"""Create X_train and X_val"""

col = ['seniority', 'income', 'assets', 'records', 'job', 'home']

X_train = OHE_DV(df_train, col)
X_val = OHE_DV_wo_fit(df_val, col)

X_train[2]

X_train.shape

dv.get_feature_names()

"""Train model"""

model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)
model.fit(X_train, y_train)

y_pred_val = model.predict_proba(X_val)[:,1]

"""ANS Q2:

--------------------------------------------------------------------------
"""

auc_q2 = roc_auc_score(y_val, y_pred_val).round(3)
print('AUC for Q2 =', auc_q2)

"""Evaluation

-------------------------------------------------------------------------
"""

eval_scores = []
thresholds = np.linspace(0,1,101)

for t in thresholds:
  actual_positive = (y_val == 1)
  actual_negative = (y_val == 0)
    
  predict_positive = (y_pred_val >= t)
  predict_negative = (y_pred_val < t)

  tp = (predict_positive & actual_positive).sum()
  tn = (predict_negative & actual_negative).sum()

  fp = (predict_positive & actual_negative).sum()
  fn = (predict_negative & actual_positive).sum()

  #TPR & FPR
  tpr = tp / (tp + fn)
  fpr = fp / (fp + tn)
  
  #Precision & Recall
  p = tp / (tp + fp)
  r = tp / (tp + fn)

  F1 = 2 * p * r / (p + r)

  eval_scores.append((t, tp, fp, fn, tn, tpr, fpr, p, r, F1))

columns = ['threshold', 'tp', 'fp', 'fn', 'tn', 'tpr', 'fpr', 'precision', 'recall', 'F1']
df_eval_scores = pd.DataFrame(eval_scores, columns=columns)

df_eval_scores.head(5)

"""ANS Q3:

----------------------------------------------------------------
"""

plt.plot(df_eval_scores.threshold, df_eval_scores.precision, label='Precision')
plt.plot(df_eval_scores.threshold, df_eval_scores.recall, label='Recall')
plt.legend()
plt.grid()

"""ANS Q4:

--------------------------------------------------------------------
"""

round(df_eval_scores.F1.max(), 3)

plt.plot(df_eval_scores.threshold, df_eval_scores.F1, label='F1')
plt.legend()
plt.grid()

"""Train and Predict Function

---------------------------------------------------------------------
"""

def train(df_train, y_train, col, C=1.0):
    dicts = df_train[col].to_dict(orient='records')
    
    dv = DictVectorizer(sparse=False)
    X_train = dv.fit_transform(dicts)
    
    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)
    model.fit(X_train, y_train)
    
    return dv, model

def predict(df, dv, model, col):
    dicts = df[col].to_dict(orient='records')
    
    X_data = dv.transform(dicts)
    y_pred = model.predict_proba(X_data)[:, 1]

    return y_pred

"""ANS Q5:

------------------------------------------------------------------
"""

col_cat = ['records', 'job', 'home']
col_num = ['seniority', 'income', 'assets']

kfold = KFold(n_splits=5, shuffle=True, random_state=1)
scores = []
C = 1.0
for train_idx, val_idx in kfold.split(df_full_train):
    df_train_q5 = df_full_train.iloc[train_idx]
    df_val_q5 = df_full_train.iloc[val_idx]

    y_train_q5 = df_train_q5.default.values
    y_val_q5 = df_val_q5.default.values

    dv, model_q5 = train(df_train_q5, y_train_q5, col, C=C)
    y_pred_q5 = predict(df_val_q5, dv, model_q5, col)

    auc_q5 = roc_auc_score(y_val_q5, y_pred_q5)
    scores.append(auc_q5)

print('C = %5s | Mean = %.3f | STD = +- %.3f' % (C, np.mean(scores), np.std(scores)))

"""ANS Q6:

------------------------------------------------------------------------------------
"""

for C in tqdm([0.01, 0.1, 1, 10]):
    kfold = KFold(n_splits=5, shuffle=True, random_state=1)

    scores = []

    for train_idx, val_idx in kfold.split(df_full_train):
        df_train_q6 = df_full_train.iloc[train_idx]
        df_val_q6 = df_full_train.iloc[val_idx]

        y_train_q6 = df_train_q6.default.values
        y_val_q6 = df_val_q6.default.values

        dv, model_q6 = train(df_train_q6, y_train_q6, col, C=C)
        y_pred_q6 = predict(df_val_q6, dv, model_q6, col)

        auc_q6 = roc_auc_score(y_val_q6, y_pred_q6)
        scores.append(auc_q6)

    print('C = %5s | Mean = %.3f | STD = +- %.3f' % (C, np.mean(scores), np.std(scores)))