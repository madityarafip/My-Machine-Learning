# -*- coding: utf-8 -*-
"""MLZoomcamp_HW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vQblrUo_bHOmC0MmArHPbM4VPd3WRYC3
"""

import pandas as pd
import numpy as np
 
import seaborn as sns
from matplotlib import pyplot as plt

from sklearn.model_selection import train_test_split

from sklearn.metrics import mutual_info_score

from sklearn.feature_extraction import DictVectorizer

from sklearn.linear_model import LogisticRegression, Ridge

"""Get The Data: New York City Airbnb Open Data"""

!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv

df = pd.read_csv('AB_NYC_2019.csv')
df.head(3)

HW_columns = [
              'neighbourhood_group',
              'room_type',
              'latitude',
              'longitude',
              'price',
              'minimum_nights',
              'number_of_reviews',
              'reviews_per_month',
              'calculated_host_listings_count',
              'availability_365'
              ]
HW_df = df[HW_columns]
HW_df.head(3)

HW_df.columns

HW_df.isna().sum()

"""------------------------------------------------------------------------------
Fill Missing Values 
"""

def X_fill_NA(df, base, val):
  df_fill = df[base]
  df_fill = df_fill.fillna(val)

  return df_fill

HW_df = X_fill_NA(HW_df, HW_columns, val=0)
HW_df.isna().sum()

"""------------------------------------------------------------------------------
ANS Q1:
"""

HW_df.neighbourhood_group.mode()

"""------------------------------------------------------------------------------
Split Data (Sklearn Library)
"""

#80% Full Train, 20% Test
df_full_train, df_test = train_test_split(HW_df, test_size=0.2, random_state=42)

"""------------------------------------------------------------------------------
Make price binary
"""

df_full_train['above_average'] = (df_full_train.price >= 152).astype(int)
df_full_train.head(10)

#60% Train, 20% Val (25% from Full Train -> 20%/80%)
df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)

y_train = df_train.above_average.values
y_val = df_val.above_average.values

y_train_q6 = np.log1p(df_train.price.values)
y_val_q6 = np.log1p(df_val.price.values)
y_test = np.log1p(df_test.price.values)

del df_train['price']
del df_val['price']
del df_test['price']

print('Train Full:', len(df_full_train), 
      '(', (len(df_full_train)/len(HW_df))*100, '%)') 
print('Train:', len(df_train), 
      '(', (len(df_train)/len(HW_df))*100, '%)') 
print('Validation:', len(df_val), 
      '(', (len(df_val)/len(HW_df))*100, '%)') 
print('Test:', len(df_test), 
      '(', (len(df_test)/len(HW_df))*100, '%)')

"""------------------------------------------------------------------------------
ANS Q2:
"""

corr_train = df_full_train.corr()
corr_train

"""------------------------------------------------------------------------------
ANS Q3:
"""

categorical = ['neighbourhood_group', 'room_type']

df_train[categorical].nunique()

df_train[categorical]

def mutual_info_price_scores(series):
  return mutual_info_score(series, df_full_train.above_average)

MI = df_full_train[categorical].apply(mutual_info_price_scores)
round(MI.sort_values(ascending=False), 2)

numerical = ['latitude',
             'longitude',
             'minimum_nights',
             'number_of_reviews',
             'reviews_per_month',
             'calculated_host_listings_count',
             'availability_365']

dv = DictVectorizer(sparse=False)

"""------------------------------------------------------------------------------
OHE for Categorical Data, and Create X_train and X_val
"""

def OHE_DV(df):
  dicts = df[categorical+numerical].to_dict(orient='records')
  X_data = dv.fit_transform(dicts)

  return X_data

X_train = OHE_DV(df_train)
X_train[0]

X_val = OHE_DV(df_val)
X_val.shape

dv.get_feature_names()

"""------------------------------------------------------------------------------
ANS Q4:
"""

model = LogisticRegression(solver='liblinear', C=1.0, random_state=42, max_iter=1000)
model.fit(X_train, y_train)

y_pred_val = model.predict(X_val)
y_pred_val

from sklearn.metrics import accuracy_score

acc = accuracy_score(y_pred_val, y_val)
print('Model Accuracy : ', round(acc, 2))

"""-------------------------------------------------------------------------------
ANS Q5:
"""

df_train.head(1)

def OHE_DV_q5(df,elim):
  dicts = df[categorical+numerical]
  del dicts[elim]
  
  dicts = dicts.to_dict(orient='records')
  
  X_data = dv.fit_transform(dicts)

  return X_data

elim = ['neighbourhood_group', 'room_type',
        'number_of_reviews', 'reviews_per_month'
        ]

for e in elim:
  print(e)

df_train_q5 = df_train
  df_val_q5 = df_val

df_train_q5.head(1)

acc_list_q5 = []

for e in elim:

  df_train_q5 = df_train
  df_val_q5 = df_val

  X_train_q5 = OHE_DV_q5(df_train_q5, e)
  X_val_q5 = OHE_DV_q5(df_val_q5, e)

  model_q5 = LogisticRegression(solver='liblinear', C=1.0, random_state=42, max_iter=1000)
  model_q5.fit(X_train_q5, y_train)

  y_pred_val_q5 = model_q5.predict(X_val_q5)
  
  acc_q5 = accuracy_score(y_pred_val_q5, y_val)

  print(e, X_train_q5.shape, X_val_q5.shape, round(acc_q5, 2))

  acc_list_q5.append(round(acc_q5, 2))

acc_list_q5

acc_diff = round(acc, 2) - acc_list_q5
acc_diff = acc_diff.tolist()
acc_diff

"""------------------------------------------------------------------------------
ANS Q6:
"""

def RMSE(y, y_pred):
  e = y_pred - y
  mse = (e ** 2).mean()
  rmse_val = np.sqrt(mse)

  return rmse_val

RMSE_list = []
for alpha in [0, 0.01, 0.1, 1, 10]:
  X_train_q6 = OHE_DV(df_train)
  X_val_q6 = OHE_DV(df_val)

  model_q6 = Ridge(alpha=alpha, solver='svd')
  model_q6.fit(X_train_q6, y_train_q6)

  y_pred_val_q6 = model_q6.predict(X_val_q6)

  RMSE_score = round(RMSE(y_val_q6, y_pred_val_q6), 3)

  RMSE_list.append(RMSE_score)

  print('Alpha = %4s' %alpha, '-> RMSE value = ', RMSE_score)