# -*- coding: utf-8 -*-
"""Proyek2_ML_Pengembangan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mnh9wFpPtJPGAiUVa2B_Ko0dckDRi6yn

# Proyek 2: Membuat Model ML dengan Data Time Series
---

Oleh: Mohammad Aditya Rafi Pratama (madityarafip - madityarafip31@gmail.com) - Depok, Indonesia

Pada proyek ini akan dirancang sebuah model Machine Learning yang bertujuan untuk konsumsi daya setiap jam menggunakan rangakaian data time series.
---

---

Proses pertama adalah import library yang digunakan
"""

import tensorflow as tf
from tensorflow.keras.layers import LSTM,Dense,Bidirectional,Dropout,Conv1D

import pandas as pd

import matplotlib.pyplot as plt

import numpy as np

from sklearn.model_selection import train_test_split

from google.colab import files

"""Dengan memanfaatkan library yang tersedia pada Google Colab, dataset yang diperlukan akan diupload menggunakan fungsi upload."""

uploaded = files.upload()

"""Setelah data berhasil diload, langkah selanjutnya adalah membaca file .csv dari dataset yang digunakan dengan menggunakan fungsi yang terdapat pada library pandas."""

d_ts = pd.read_csv('DOM_hourly.csv')
d_ts.head()

"""Dapat dilihat pada tampilan data terdapat 2 kolom yang terbaca yaitu kolom Datetime dan DOM_MW yang menunjukkan pemakaian energi setiap jamnya. Selanjutnya kita akan melihat jumlah data dan apakah terdapat *missing value* di dalam dataset tersebut."""

d_ts.shape

d_ts.isnull().sum()

"""Karena dari pengecekan tidak terdapat *missing value* maka dapat dilanjutkan ke proses selanjutnya yaitu plot data. Pertama data waktu harus diubah menjadi format datetime, dan proses ini dapat dilakukan dengan menggunakan library 

```
pd.to_datetime(dataset)
```


"""

d_ts['Datetime']=pd.to_datetime(d_ts['Datetime'])
d_ts['Datetime'].head()

"""Karena pada plot data jam tidak dibutuhkan maka kolom Datetime akan diganti menjadi data tanggal dan menjadikannya index menggunakan library berikut

```
dataset.set_index()
```


"""

data_plot = d_ts[['Datetime','DOM_MW']].copy()
data_plot['date'] = data_plot['Datetime'].dt.date

data_plot=data_plot.drop('Datetime',axis=1)
data_plot.set_index('date', inplace= True)
data_plot.head()

"""Dan sekarang masuk ke proses plot data konsumsi energi setiap jam."""

plt.figure(figsize=(25, 8))
plt.plot(data_plot)
plt.title('Energy Consumption')
plt.xlabel('Date')
plt.ylabel('Energy')
plt.show()

"""Proses selanjutnya adalah membagi data 
training dan data testing
"""

date_time = d_ts['Datetime']
temp = d_ts['DOM_MW']

x_train, x_test, y_train, y_test = train_test_split(temp, date_time, test_size=0.2)
print('Train Data       : ', len(x_train))
print('Validation Data  : ', len(x_test))

"""Fungsi berikut yang dapat merubah data menjadi format yang dapat diterima oleh model. Fungsi ini menerima sebuah series/atribut yang telah dikonversi menjadi tipe numpy, lalu mengembalikan label dan atribut dari dataset dalam bentuk batch."""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

shuffle_buffer_size = 1000
window_size = 64
batch_size = 256
train = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
val = windowed_dataset(x_test, window_size, batch_size, shuffle_buffer_size)

"""Sebelum masuk proses melatih/training model dibutuhkan proses callback yang berfungi untuk memberhentikan proses pelatihan ketika mencapai akurasi yang ditentukan, yang dimana pada proyek ini akan berhenti ketika mencapai MAE < 10% skala data."""

class MeineCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('mae') < mae_min  and logs.get('val_mae') < mae_min):
            self.model.stop_training = True
            print("Training complete! Reached < 10% of data scale")

callback = MeineCallback()

"""10% dari skala data didapatkan dengan menggunakan program berikut."""

ener_max = temp.max()
ener_min = temp.min()
limit_percentage_of_data = 10/100

mae_min = (ener_max - ener_min) * limit_percentage_of_data
print('10% from data = ', mae_min)

"""Selanjutnya untuk arsitektur model gunakan 2 buah layer Biderectional-LSTM. Ketika menggunakan 2 buah layer LSTM, perhatikan bahwa layer pertama harus memiliki parameter return_sequences yang bernilai True."""

model = tf.keras.models.Sequential([
                    Conv1D(filters=60, kernel_size=5,
                           strides=1, padding='causal',
                           activation='relu', input_shape=[None, 1]),
                    Bidirectional(LSTM(60, return_sequences=True)),
                    Bidirectional(LSTM(60)),
                    Dense(30, activation="relu"),
                    Dense(10, activation="relu"),
                    Dense(1)
                  ])
model.summary()

"""Proses selanjutnya adalah melatih model dengan menggunakan fungsi fit(). Pada proses ini juga akan dimasukkan nilai Epoch yang diinginkan dengan fungsi

```
input()
```
Selain itu, pada proses ini digunakan juga optimizer dengan ditambah *Learning Rate* dan *Momentum* sebagai hyperparameter dari proses pelatihan.

"""

num_epochs = int(input('Epoch = '))
print(' ')
optimizer = tf.keras.optimizers.SGD(lr=1.2500e-05, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])
history = model.fit(train,
                    epochs=num_epochs,
                    callbacks=[callback], 
                    validation_data=val, 
                    verbose=1
                    )

"""Setelah proses training selesai, proses selanjutnya adalah melihat apakah nilai MAE dari *train* dan *validation* sudah memenuhi kriteria < 10% sampel data."""

last_mae_train = history.history['mae'][-1]
last_mae_val = history.history['val_mae'][-1]

percentage_mae_result = last_mae_train / (ener_max - ener_min)
percentage_mae_result = percentage_mae_result*100
print('MAE training   = ', percentage_mae_result, '%')

percentage_val_mae_result = last_mae_val / (ener_max - ener_min)
percentage_val_mae_result = percentage_val_mae_result*100
print('MAE validation = ', percentage_val_mae_result, '%')

"""Selanjutnya adalah proses plot nilai loss dan MAE pada epoch yang berjalan"""

plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('MAE')
plt.ylabel('mae')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()